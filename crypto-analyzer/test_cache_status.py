"""
æµ‹è¯•ç¼“å­˜çŠ¶æ€è„šæœ¬
æ£€æŸ¥ç¼“å­˜è¡¨æ•°æ®å’ŒAPIå“åº”
"""

import sys
from pathlib import Path
import asyncio
import yaml
from datetime import datetime
from sqlalchemy import create_engine, text
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = project_root / "config.yaml"
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)


def get_db_connection(config):
    """è·å–æ•°æ®åº“è¿æ¥ï¼ˆä¸DatabaseServiceå®Œå…¨ç›¸åŒçš„æ–¹å¼ï¼‰"""
    from urllib.parse import quote_plus

    # æŒ‰ç…§ DatabaseService çš„æ–¹å¼è¯»å–é…ç½®
    db_config = config.get('database', {})
    mysql_config = db_config.get('mysql', {})

    host = mysql_config.get('host', 'localhost')
    port = mysql_config.get('port', 3306)
    user = mysql_config.get('user', 'root')
    password = mysql_config.get('password', '')
    database = mysql_config.get('database', 'binance-data')

    logger.info(f"\nğŸ“Š æ•°æ®åº“é…ç½®:")
    logger.info(f"   Host: {host}")
    logger.info(f"   Port: {port}")
    logger.info(f"   User: {user}")
    logger.info(f"   Database: {database}")
    logger.info(f"   Password: {'*' * len(password) if password else '(ç©º)'}")

    # URLç¼–ç å¯†ç ä»¥å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼ˆä¸DatabaseServiceå®Œå…¨ç›¸åŒï¼‰
    password_encoded = quote_plus(password)

    # åˆ›å»ºè¿æ¥å­—ç¬¦ä¸²ï¼ˆä¸DatabaseServiceå®Œå…¨ç›¸åŒï¼‰
    db_uri = f"mysql+pymysql://{user}:{password_encoded}@{host}:{port}/{database}?charset=utf8mb4"

    return create_engine(
        db_uri,
        pool_pre_ping=True,  # è‡ªåŠ¨æ£€æµ‹è¿æ¥æ˜¯å¦æœ‰æ•ˆ
        echo=False
    )


def check_cache_tables(engine):
    """æ£€æŸ¥ç¼“å­˜è¡¨æ˜¯å¦å­˜åœ¨"""
    logger.info("\n" + "="*80)
    logger.info("1ï¸âƒ£  æ£€æŸ¥ç¼“å­˜è¡¨æ˜¯å¦å­˜åœ¨")
    logger.info("="*80)

    cache_tables = [
        'price_stats_24h',
        'technical_indicators_cache',
        'news_sentiment_aggregation',
        'funding_rate_stats',
        'hyperliquid_symbol_aggregation',
        'investment_recommendations_cache'
    ]

    with engine.connect() as conn:
        for table in cache_tables:
            try:
                result = conn.execute(text(f"SHOW TABLES LIKE '{table}'"))
                exists = result.fetchone() is not None

                if exists:
                    # æ£€æŸ¥è®°å½•æ•°
                    count_result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
                    count = count_result.fetchone()[0]

                    # æ£€æŸ¥æœ€åæ›´æ–°æ—¶é—´
                    if table != 'price_stats_24h':  # price_stats_24hæ²¡æœ‰updated_atå­—æ®µ
                        time_result = conn.execute(text(
                            f"SELECT MAX(updated_at) FROM {table}"
                        ))
                        last_update = time_result.fetchone()[0]
                        logger.info(f"  âœ… {table:40s} | è®°å½•æ•°: {count:5d} | æœ€åæ›´æ–°: {last_update}")
                    else:
                        logger.info(f"  âœ… {table:40s} | è®°å½•æ•°: {count:5d}")
                else:
                    logger.error(f"  âŒ {table:40s} | è¡¨ä¸å­˜åœ¨")
            except Exception as e:
                logger.error(f"  âŒ {table:40s} | é”™è¯¯: {e}")


def check_investment_recommendations_cache(engine):
    """æ£€æŸ¥æŠ•èµ„å»ºè®®ç¼“å­˜è¡¨è¯¦ç»†æ•°æ®"""
    logger.info("\n" + "="*80)
    logger.info("2ï¸âƒ£  æ£€æŸ¥æŠ•èµ„å»ºè®®ç¼“å­˜è¡¨æ•°æ®")
    logger.info("="*80)

    with engine.connect() as conn:
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            result = conn.execute(text("SHOW TABLES LIKE 'investment_recommendations_cache'"))
            if not result.fetchone():
                logger.error("  âŒ investment_recommendations_cache è¡¨ä¸å­˜åœ¨ï¼")
                logger.info("\n  ğŸ’¡ è¯·å…ˆæ‰§è¡ŒSQLè„šæœ¬åˆ›å»ºç¼“å­˜è¡¨:")
                logger.info("     mysql < scripts/migrations/001_create_cache_tables.sql")
                return

            # æ£€æŸ¥è®°å½•æ•°
            count_result = conn.execute(text("SELECT COUNT(*) FROM investment_recommendations_cache"))
            count = count_result.fetchone()[0]

            if count == 0:
                logger.warning("  âš ï¸  investment_recommendations_cache è¡¨ä¸ºç©ºï¼")
                logger.info("\n  ğŸ’¡ è¯·è¿è¡Œç¼“å­˜æ›´æ–°æœåŠ¡:")
                logger.info("     python scripts/ç®¡ç†/update_cache_manual.py")
                return

            logger.info(f"  âœ… ç¼“å­˜è¡¨è®°å½•æ•°: {count}")

            # æŸ¥è¯¢å‰5æ¡æ•°æ®ï¼ˆsignalæ˜¯MySQLä¿ç•™å­—ï¼Œéœ€è¦ç”¨åå¼•å·ï¼‰
            query = text("""
                SELECT
                    symbol,
                    `signal`,
                    confidence,
                    total_score,
                    technical_score,
                    news_score,
                    funding_score,
                    hyperliquid_score,
                    current_price,
                    risk_level,
                    updated_at
                FROM investment_recommendations_cache
                ORDER BY confidence DESC
                LIMIT 5
            """)

            result = conn.execute(query)
            rows = result.fetchall()

            logger.info("\n  ğŸ“Š æŠ•èµ„å»ºè®®ç¼“å­˜æ•°æ® (Top 5):")
            logger.info("  " + "-"*120)
            logger.info(f"  {'å¸ç§':<12} {'ä¿¡å·':<15} {'ç½®ä¿¡åº¦':<8} {'æ€»åˆ†':<8} {'æŠ€æœ¯':<8} {'æ–°é—»':<8} {'èµ„é‡‘':<8} {'ä»·æ ¼':<12} {'æ›´æ–°æ—¶é—´':<20}")
            logger.info("  " + "-"*120)

            for row in rows:
                symbol = row[0]
                signal = row[1] or 'N/A'
                confidence = f"{row[2]:.1f}%" if row[2] else 'N/A'
                total_score = f"{row[3]:.1f}" if row[3] else 'N/A'
                tech_score = f"{row[4]:.1f}" if row[4] else 'N/A'
                news_score = f"{row[5]:.1f}" if row[5] else 'N/A'
                fund_score = f"{row[6]:.1f}" if row[6] else 'N/A'
                price = f"${row[8]:,.2f}" if row[8] else 'N/A'
                updated = row[10].strftime('%Y-%m-%d %H:%M:%S') if row[10] else 'N/A'

                logger.info(f"  {symbol:<12} {signal:<15} {confidence:<8} {total_score:<8} {tech_score:<8} {news_score:<8} {fund_score:<8} {price:<12} {updated:<20}")

            logger.info("  " + "-"*120)

        except Exception as e:
            logger.error(f"  âŒ æ£€æŸ¥æŠ•èµ„å»ºè®®ç¼“å­˜è¡¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()


def check_original_table(engine):
    """æ£€æŸ¥åŸå§‹æŠ•èµ„å»ºè®®è¡¨"""
    logger.info("\n" + "="*80)
    logger.info("3ï¸âƒ£  æ£€æŸ¥åŸå§‹æŠ•èµ„å»ºè®®è¡¨")
    logger.info("="*80)

    with engine.connect() as conn:
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            result = conn.execute(text("SHOW TABLES LIKE 'investment_recommendations'"))
            if not result.fetchone():
                logger.warning("  âš ï¸  investment_recommendations è¡¨ä¸å­˜åœ¨")
                return

            # æ£€æŸ¥è®°å½•æ•°
            count_result = conn.execute(text("SELECT COUNT(*) FROM investment_recommendations"))
            count = count_result.fetchone()[0]
            logger.info(f"  â„¹ï¸  åŸå§‹è¡¨è®°å½•æ•°: {count}")

            if count > 0:
                # æŸ¥è¯¢æœ€åæ›´æ–°æ—¶é—´
                time_result = conn.execute(text("SELECT MAX(updated_at) FROM investment_recommendations"))
                last_update = time_result.fetchone()[0]
                logger.info(f"  â„¹ï¸  æœ€åæ›´æ–°æ—¶é—´: {last_update}")

        except Exception as e:
            logger.error(f"  âŒ æ£€æŸ¥åŸå§‹è¡¨å¤±è´¥: {e}")


async def check_api_response():
    """æ£€æŸ¥APIå“åº”"""
    logger.info("\n" + "="*80)
    logger.info("4ï¸âƒ£  æ£€æŸ¥APIå“åº”")
    logger.info("="*80)

    try:
        import aiohttp

        async with aiohttp.ClientSession() as session:
            # æµ‹è¯• /api/dashboard
            url = "http://localhost:9020/api/dashboard"
            logger.info(f"  ğŸ”— è¯·æ±‚: {url}")

            start_time = datetime.now()
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                elapsed = (datetime.now() - start_time).total_seconds()

                if response.status == 200:
                    data = await response.json()

                    logger.info(f"  âœ… APIå“åº”æˆåŠŸ ({elapsed:.2f}ç§’)")

                    # æ£€æŸ¥è¿”å›æ•°æ®
                    if data.get('success'):
                        dashboard_data = data.get('data', {})
                        recommendations = dashboard_data.get('recommendations', [])

                        logger.info(f"\n  ğŸ“Š Dashboardæ•°æ®:")
                        logger.info(f"     ä»·æ ¼æ•°æ®: {len(dashboard_data.get('prices', []))} ä¸ª")
                        logger.info(f"     æŠ•èµ„å»ºè®®: {len(recommendations)} ä¸ª")
                        logger.info(f"     æ–°é—»æ•°æ®: {len(dashboard_data.get('news', []))} æ¡")
                        logger.info(f"     æœ€åæ›´æ–°: {dashboard_data.get('last_updated', 'N/A')}")

                        if recommendations:
                            logger.info(f"\n  ğŸ’¡ æŠ•èµ„å»ºè®®ç¤ºä¾‹ (å‰3ä¸ª):")
                            for i, rec in enumerate(recommendations[:3], 1):
                                symbol = rec.get('symbol', 'N/A')
                                signal = rec.get('signal', 'N/A')
                                confidence = rec.get('confidence', 0)
                                logger.info(f"     {i}. {symbol}: {signal} (ç½®ä¿¡åº¦: {confidence:.1f}%)")
                        else:
                            logger.warning("\n  âš ï¸  APIè¿”å›çš„æŠ•èµ„å»ºè®®ä¸ºç©ºï¼")
                            logger.info("\n  å¯èƒ½çš„åŸå› :")
                            logger.info("     1. ç¼“å­˜è¡¨æ²¡æœ‰æ•°æ® - è¿è¡Œ: python scripts/ç®¡ç†/update_cache_manual.py")
                            logger.info("     2. scheduler.py æœªè¿è¡Œ - å¯åŠ¨: python app/scheduler.py")
                            logger.info("     3. EnhancedDashboard åˆå§‹åŒ–å¤±è´¥ - æ£€æŸ¥ main.py æ—¥å¿—")
                    else:
                        logger.error(f"  âŒ APIè¿”å›å¤±è´¥: {data.get('error', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    logger.error(f"  âŒ APIå“åº”å¤±è´¥: HTTP {response.status}")

    except aiohttp.ClientConnectorError:
        logger.error("  âŒ æ— æ³•è¿æ¥åˆ°APIæœåŠ¡å™¨")
        logger.info("  ğŸ’¡ è¯·ç¡®ä¿ FastAPI æœåŠ¡æ­£åœ¨è¿è¡Œ:")
        logger.info("     python app/main.py")
    except asyncio.TimeoutError:
        logger.error("  âŒ APIè¯·æ±‚è¶…æ—¶")
    except Exception as e:
        logger.error(f"  âŒ APIæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def check_scheduler_status():
    """æ£€æŸ¥è°ƒåº¦å™¨çŠ¶æ€"""
    logger.info("\n" + "="*80)
    logger.info("5ï¸âƒ£  æ£€æŸ¥è°ƒåº¦å™¨è¿›ç¨‹")
    logger.info("="*80)

    import subprocess

    try:
        # åœ¨Windowsä¸Šä½¿ç”¨ä¸åŒçš„å‘½ä»¤
        if sys.platform == 'win32':
            result = subprocess.run(
                ['tasklist', '/FI', 'IMAGENAME eq python.exe'],
                capture_output=True,
                text=True
            )

            if 'scheduler.py' in result.stdout:
                logger.info("  âœ… scheduler.py æ­£åœ¨è¿è¡Œ")
            else:
                logger.warning("  âš ï¸  scheduler.py æœªè¿è¡Œ")
                logger.info("  ğŸ’¡ å¯åŠ¨è°ƒåº¦å™¨: python app/scheduler.py")
        else:
            # Linux/Mac
            result = subprocess.run(
                ['ps', 'aux'],
                capture_output=True,
                text=True
            )

            if 'scheduler.py' in result.stdout:
                logger.info("  âœ… scheduler.py æ­£åœ¨è¿è¡Œ")
            else:
                logger.warning("  âš ï¸  scheduler.py æœªè¿è¡Œ")
                logger.info("  ğŸ’¡ å¯åŠ¨è°ƒåº¦å™¨: python app/scheduler.py")

    except Exception as e:
        logger.warning(f"  âš ï¸  æ— æ³•æ£€æŸ¥è¿›ç¨‹çŠ¶æ€: {e}")


def print_recommendations():
    """æ‰“å°ä¿®å¤å»ºè®®"""
    logger.info("\n" + "="*80)
    logger.info("ğŸ’¡ ä¿®å¤å»ºè®®")
    logger.info("="*80)

    logger.info("\nå¦‚æœæŠ•èµ„å»ºè®®æ•°æ®ä¸ºç©ºï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
    logger.info("\n1ï¸âƒ£  åˆ›å»ºç¼“å­˜è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰:")
    logger.info("   mysql -h <host> -u <user> -p<password> <database> < scripts/migrations/001_create_cache_tables.sql")

    logger.info("\n2ï¸âƒ£  æ‰‹åŠ¨æ›´æ–°ç¼“å­˜ï¼ˆç«‹å³ç”Ÿæ•ˆï¼‰:")
    logger.info("   python scripts/ç®¡ç†/update_cache_manual.py")

    logger.info("\n3ï¸âƒ£  å¯åŠ¨è°ƒåº¦å™¨ï¼ˆè‡ªåŠ¨æ›´æ–°ï¼‰:")
    logger.info("   python app/scheduler.py")

    logger.info("\n4ï¸âƒ£  å¯åŠ¨APIæœåŠ¡:")
    logger.info("   python app/main.py")

    logger.info("\n5ï¸âƒ£  è®¿é—®Dashboard:")
    logger.info("   http://localhost:9020/dashboard")

    logger.info("\n" + "="*80 + "\n")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("\n")
    logger.info("ğŸ” " + "="*76)
    logger.info("ğŸ”  ç¼“å­˜çŠ¶æ€æ£€æŸ¥å·¥å…·")
    logger.info("ğŸ” " + "="*76)
    logger.info(f"   æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("ğŸ” " + "="*76)

    try:
        # åŠ è½½é…ç½®
        config = load_config()

        # è·å–æ•°æ®åº“è¿æ¥
        engine = get_db_connection(config)

        # 1. æ£€æŸ¥ç¼“å­˜è¡¨
        check_cache_tables(engine)

        # 2. æ£€æŸ¥æŠ•èµ„å»ºè®®ç¼“å­˜è¡¨
        check_investment_recommendations_cache(engine)

        # 3. æ£€æŸ¥åŸå§‹è¡¨
        check_original_table(engine)

        # 4. æ£€æŸ¥APIå“åº”
        asyncio.run(check_api_response())

        # 5. æ£€æŸ¥è°ƒåº¦å™¨çŠ¶æ€
        check_scheduler_status()

        # 6. æ‰“å°ä¿®å¤å»ºè®®
        print_recommendations()

    except Exception as e:
        logger.error(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
