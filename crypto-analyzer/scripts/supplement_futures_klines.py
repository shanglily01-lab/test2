#!/usr/bin/env python3
"""
æ•°æ®è¡¥å……é‡‡é›†è„šæœ¬ - é‡‡é›†æœ€è¿‘7å¤©çš„åˆçº¦Kçº¿æ•°æ®
é‡‡é›†æ‰€æœ‰äº¤æ˜“å¯¹çš„ 5m/15m/1h æ—¶é—´å‘¨æœŸæ•°æ®
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import asyncio
import yaml
import pymysql
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import pandas as pd
import requests
from loguru import logger

# ç¡®ä¿æ§åˆ¶å°è¾“å‡ºä½¿ç”¨UTF-8ç¼–ç 
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')


class FuturesKlinesSupplementer:
    """åˆçº¦Kçº¿æ•°æ®è¡¥å……é‡‡é›†å™¨"""

    def __init__(self, config_path='config.yaml'):
        """
        åˆå§‹åŒ–

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½é…ç½®
        config_file = Path(config_path)
        if not config_file.exists():
            config_file = project_root / 'config.yaml'
        
        with open(config_file, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)

        # è·å–äº¤æ˜“å¯¹åˆ—è¡¨
        self.symbols = self.config.get('symbols', [])
        print(f"ğŸ“Š é…ç½®äº¤æ˜“å¯¹: {len(self.symbols)} ä¸ª")
        print(f"   äº¤æ˜“å¯¹åˆ—è¡¨: {', '.join(self.symbols)}")

        # æ—¶é—´å‘¨æœŸ
        self.timeframes = ['5m', '15m', '1h']
        print(f"ğŸ“… æ—¶é—´å‘¨æœŸ: {', '.join(self.timeframes)}")

        # æ•°æ®åº“é…ç½®
        db_config = self.config.get('database', {}).get('mysql', {})
        self.db_config = {
            'host': db_config.get('host', 'localhost'),
            'port': db_config.get('port', 3306),
            'user': db_config.get('user', 'root'),
            'password': db_config.get('password', ''),
            'database': db_config.get('database', 'binance-data'),
            'charset': 'utf8mb4',
            'cursorclass': pymysql.cursors.DictCursor
        }

        # Binance Futures API
        self.base_url = "https://fapi.binance.com"

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'success_requests': 0,
            'failed_requests': 0,
            'total_klines': 0,
            'saved_klines': 0,
            'skipped_klines': 0
        }

    def connect_db(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            connection = pymysql.connect(**self.db_config)
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            return connection
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    def calculate_klines_needed(self, timeframe: str, days: int) -> int:
        """
        è®¡ç®—æŒ‡å®šå¤©æ•°éœ€è¦çš„Kçº¿æ•°é‡

        Args:
            timeframe: æ—¶é—´å‘¨æœŸ (5m, 15m, 1hç­‰)
            days: å¤©æ•°

        Returns:
            Kçº¿æ•°é‡
        """
        timeframe_minutes = {
            '1m': 1,
            '5m': 5,
            '15m': 15,
            '30m': 30,
            '1h': 60,
            '4h': 240,
            '1d': 1440
        }
        minutes = timeframe_minutes.get(timeframe, 60)
        return int(days * 24 * 60 / minutes)

    async def fetch_klines_batch(
        self,
        symbol: str,
        timeframe: str,
        start_time: datetime,
        end_time: datetime,
        limit: int = 1500
    ) -> Optional[pd.DataFrame]:
        """
        æ‰¹é‡è·å–Kçº¿æ•°æ®

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´å‘¨æœŸ
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            limit: æ¯æ¬¡è¯·æ±‚çš„æœ€å¤§æ•°é‡ï¼ˆå¸å®‰é™åˆ¶1500ï¼‰

        Returns:
            DataFrameåŒ…å«Kçº¿æ•°æ®
        """
        try:
            binance_symbol = symbol.replace('/', '')
            url = f"{self.base_url}/fapi/v1/klines"
            
            all_klines = []
            current_start = start_time

            batch_num = 0
            while current_start < end_time:
                batch_num += 1
                params = {
                    'symbol': binance_symbol,
                    'interval': timeframe,
                    'startTime': int(current_start.timestamp() * 1000),
                    'endTime': int(end_time.timestamp() * 1000),
                    'limit': limit
                }

                self.stats['total_requests'] += 1
                print(f"    ğŸ“¡ è¯·æ±‚æ‰¹æ¬¡ {batch_num}: {current_start.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_time.strftime('%Y-%m-%d %H:%M:%S')}", end='\r')
                sys.stdout.flush()
                
                try:
                    response = await asyncio.wait_for(
                        asyncio.to_thread(requests.get, url, params=params, timeout=30),
                        timeout=35  # æ€»è¶…æ—¶35ç§’
                    )
                except asyncio.TimeoutError:
                    logger.error(f"è·å– {symbol} {timeframe} Kçº¿è¶…æ—¶ï¼ˆæ‰¹æ¬¡ {batch_num}ï¼‰")
                    self.stats['failed_requests'] += 1
                    break
                except Exception as e:
                    logger.error(f"è·å– {symbol} {timeframe} Kçº¿è¯·æ±‚å¼‚å¸¸: {e}")
                    self.stats['failed_requests'] += 1
                    break

                if response.status_code != 200:
                    error_msg = response.text
                    logger.error(f"è·å– {symbol} {timeframe} Kçº¿å¤±è´¥: HTTP {response.status_code} - {error_msg}")
                    self.stats['failed_requests'] += 1
                    return None

                klines = response.json()
                
                if not klines:
                    break

                # è½¬æ¢ä¸ºDataFrame
                df = pd.DataFrame(klines, columns=[
                    'open_time', 'open', 'high', 'low', 'close', 'volume',
                    'close_time', 'quote_volume', 'trades', 'taker_buy_volume',
                    'taker_buy_quote_volume', 'ignore'
                ])

                # é€‰æ‹©éœ€è¦çš„åˆ—å¹¶è½¬æ¢ç±»å‹
                df = df[['open_time', 'open', 'high', 'low', 'close', 'volume', 'quote_volume', 'trades', 'close_time']].copy()
                df['timestamp'] = pd.to_datetime(df['open_time'], unit='ms')
                df['open'] = df['open'].astype(float)
                df['high'] = df['high'].astype(float)
                df['low'] = df['low'].astype(float)
                df['close'] = df['close'].astype(float)
                df['volume'] = df['volume'].astype(float)
                df['quote_volume'] = df['quote_volume'].astype(float)
                df['trades'] = df['trades'].astype(int)
                df['close_time'] = df['close_time'].astype(int)

                all_klines.append(df)
                print(f"    âœ… æ‰¹æ¬¡ {batch_num} è·å–åˆ° {len(klines)} æ¡Kçº¿ï¼ˆç´¯è®¡: {sum(len(k) for k in all_klines)} æ¡ï¼‰")
                sys.stdout.flush()

                # å¦‚æœè¿”å›çš„æ•°æ®å°‘äºlimitï¼Œè¯´æ˜å·²ç»è·å–å®Œæ‰€æœ‰æ•°æ®
                if len(klines) < limit:
                    break

                # æ›´æ–°å¼€å§‹æ—¶é—´ä¸ºæœ€åä¸€æ¡Kçº¿çš„ç»“æŸæ—¶é—´ + 1æ¯«ç§’
                last_close_time = df['close_time'].iloc[-1]
                current_start = pd.to_datetime(last_close_time, unit='ms') + pd.Timedelta(milliseconds=1)

                # é¿å…æ— é™å¾ªç¯
                if len(all_klines) > 200:  # æœ€å¤š200æ‰¹ï¼ˆ14å¤©5mæ•°æ®çº¦éœ€è¦200æ‰¹ï¼‰
                    logger.warning(f"è·å– {symbol} {timeframe} Kçº¿æ•°æ®è¿‡å¤šï¼Œåœæ­¢è·å–")
                    break

                # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                await asyncio.sleep(0.2)

            if not all_klines:
                return None

            # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„æ•°æ®
            result_df = pd.concat(all_klines, ignore_index=True)
            # å»é‡ï¼ˆæŒ‰open_timeï¼‰
            result_df = result_df.drop_duplicates(subset=['open_time'], keep='last')
            # æ’åº
            result_df = result_df.sort_values('open_time').reset_index(drop=True)

            # æ·»åŠ å…ƒæ•°æ®
            result_df['symbol'] = symbol
            result_df['exchange'] = 'binance_futures'
            result_df['timeframe'] = timeframe

            self.stats['success_requests'] += 1
            return result_df

        except Exception as e:
            logger.error(f"è·å– {symbol} {timeframe} Kçº¿å¤±è´¥: {e}")
            self.stats['failed_requests'] += 1
            return None

    def save_klines_to_db(self, connection, df: pd.DataFrame, symbol: str, timeframe: str) -> int:
        """
        ä¿å­˜Kçº¿æ•°æ®åˆ°æ•°æ®åº“ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§æ’å…¥å¤ªå¤šæ•°æ®ï¼‰

        Args:
            connection: æ•°æ®åº“è¿æ¥
            df: Kçº¿æ•°æ®DataFrame
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´å‘¨æœŸ

        Returns:
            ä¿å­˜çš„æ•°æ®æ¡æ•°
        """
        if df is None or len(df) == 0:
            return 0

        cursor = connection.cursor()
        saved_count = 0
        batch_size = 500  # æ¯æ‰¹500æ¡ï¼Œé¿å…ä¸€æ¬¡æ€§æ’å…¥å¤ªå¤š

        try:
            insert_sql = """
            INSERT INTO kline_data
                (symbol, exchange, timeframe, open_time, close_time, timestamp, 
                 open_price, high_price, low_price, close_price, volume, quote_volume, number_of_trades)
            VALUES
                (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON DUPLICATE KEY UPDATE
                open_price = VALUES(open_price),
                high_price = VALUES(high_price),
                low_price = VALUES(low_price),
                close_price = VALUES(close_price),
                volume = VALUES(volume),
                quote_volume = VALUES(quote_volume),
                number_of_trades = VALUES(number_of_trades),
                close_time = VALUES(close_time)
            """

            total_rows = len(df)
            print(f"  ğŸ’¾ å¼€å§‹ä¿å­˜ {total_rows} æ¡æ•°æ®åˆ°æ•°æ®åº“ï¼ˆåˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹ {batch_size} æ¡ï¼‰...")
            sys.stdout.flush()

            # åˆ†æ‰¹å¤„ç†
            for i in range(0, total_rows, batch_size):
                batch_df = df.iloc[i:i + batch_size]
                values = []
                
                for _, row in batch_df.iterrows():
                    values.append((
                        row['symbol'],
                        row['exchange'],
                        row['timeframe'],
                        int(row['open_time']),
                        int(row['close_time']),
                        row['timestamp'],
                        float(row['open']),
                        float(row['high']),
                        float(row['low']),
                        float(row['close']),
                        float(row['volume']),
                        float(row['quote_volume']),
                        int(row['trades'])
                    ))

                # æ‰¹é‡æ’å…¥å½“å‰æ‰¹æ¬¡
                cursor.executemany(insert_sql, values)
                connection.commit()
                batch_saved = cursor.rowcount
                saved_count += batch_saved

                # æ˜¾ç¤ºè¿›åº¦
                progress = min(i + batch_size, total_rows)
                print(f"  ğŸ“Š è¿›åº¦: {progress}/{total_rows} ({progress*100//total_rows}%) - å·²ä¿å­˜ {saved_count} æ¡", end='\r')
                sys.stdout.flush()

            print()  # æ¢è¡Œ
            self.stats['saved_klines'] += saved_count
            self.stats['total_klines'] += len(df)

        except Exception as e:
            connection.rollback()
            logger.error(f"ä¿å­˜ {symbol} {timeframe} Kçº¿æ•°æ®åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        finally:
            cursor.close()

        return saved_count

    async def supplement_symbol_timeframe(
        self,
        connection,
        symbol: str,
        timeframe: str,
        days: int = 7
    ):
        """
        è¡¥å……å•ä¸ªäº¤æ˜“å¯¹å•ä¸ªæ—¶é—´å‘¨æœŸçš„æ•°æ®

        Args:
            connection: æ•°æ®åº“è¿æ¥
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´å‘¨æœŸ
            days: å¤©æ•°
        """
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)

            print(f"\nğŸ“¥ é‡‡é›† {symbol} {timeframe} (æœ€è¿‘{days}å¤©: {start_time.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_time.strftime('%Y-%m-%d %H:%M:%S')})")
            sys.stdout.flush()

            # è·å–Kçº¿æ•°æ®
            df = await self.fetch_klines_batch(symbol, timeframe, start_time, end_time)

            if df is None or len(df) == 0:
                print(f"  âš ï¸  æœªè·å–åˆ°æ•°æ®")
                return

            print(f"  âœ… è·å–åˆ° {len(df)} æ¡Kçº¿æ•°æ®")

            # ä¿å­˜åˆ°æ•°æ®åº“
            saved_count = self.save_klines_to_db(connection, df, symbol, timeframe)
            
            if saved_count > 0:
                print(f"  ğŸ’¾ ä¿å­˜ {saved_count} æ¡æ•°æ®åˆ°æ•°æ®åº“")
            else:
                print(f"  âš ï¸  ä¿å­˜å¤±è´¥æˆ–æ•°æ®å·²å­˜åœ¨")

        except Exception as e:
            logger.error(f"è¡¥å…… {symbol} {timeframe} æ•°æ®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    async def run(self, days: int = 7):
        """
        è¿è¡Œè¡¥å……é‡‡é›†

        Args:
            days: é‡‡é›†æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®ï¼Œé»˜è®¤7å¤©
        """
        print("=" * 80)
        print("ğŸš€ å¼€å§‹è¡¥å……é‡‡é›†åˆçº¦Kçº¿æ•°æ®")
        print("=" * 80)
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: æœ€è¿‘ {days} å¤©")
        print(f"ğŸ“Š äº¤æ˜“å¯¹æ•°é‡: {len(self.symbols)}")
        print(f"â±ï¸  æ—¶é—´å‘¨æœŸ: {len(self.timeframes)} ä¸ª")
        print(f"ğŸ“ˆ é¢„è®¡ä»»åŠ¡æ•°: {len(self.symbols) * len(self.timeframes)}")
        print("=" * 80)

        connection = self.connect_db()

        try:
            total_tasks = len(self.symbols) * len(self.timeframes)
            current_task = 0

            for symbol in self.symbols:
                for timeframe in self.timeframes:
                    current_task += 1
                    print(f"\n[{current_task}/{total_tasks}] å¤„ç† {symbol} {timeframe}")

                    await self.supplement_symbol_timeframe(connection, symbol, timeframe, days)

                    # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                    await asyncio.sleep(0.5)

            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            print("\n" + "=" * 80)
            print("ğŸ“Š é‡‡é›†ç»Ÿè®¡")
            print("=" * 80)
            print(f"æ€»è¯·æ±‚æ•°: {self.stats['total_requests']}")
            print(f"æˆåŠŸè¯·æ±‚: {self.stats['success_requests']}")
            print(f"å¤±è´¥è¯·æ±‚: {self.stats['failed_requests']}")
            print(f"è·å–Kçº¿æ€»æ•°: {self.stats['total_klines']}")
            print(f"ä¿å­˜Kçº¿æ•°: {self.stats['saved_klines']}")
            print(f"è·³è¿‡Kçº¿æ•°: {self.stats['skipped_klines']}")
            print("=" * 80)
            print("âœ… è¡¥å……é‡‡é›†å®Œæˆï¼")

        except Exception as e:
            logger.error(f"è¡¥å……é‡‡é›†è¿‡ç¨‹å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        finally:
            connection.close()
            print("ğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='è¡¥å……é‡‡é›†æœ€è¿‘Nå¤©çš„åˆçº¦Kçº¿æ•°æ®')
    parser.add_argument(
        '--days',
        type=int,
        default=7,
        help='é‡‡é›†æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®ï¼ˆé»˜è®¤: 7ï¼‰'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.yamlï¼‰'
    )

    args = parser.parse_args()

    supplementer = FuturesKlinesSupplementer(config_path=args.config)
    await supplementer.run(days=args.days)


if __name__ == '__main__':
    asyncio.run(main())

