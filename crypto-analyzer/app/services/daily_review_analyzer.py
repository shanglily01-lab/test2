#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥å¤ç›˜åˆ†æå™¨ - Daily Review Analyzer

åŠŸèƒ½:
1. æ¯å¤©å¤ç›˜24Hè¡Œæƒ…èµ°åŠ¿
2. è¯†åˆ«é”™è¿‡çš„å¤§è¡Œæƒ…æœºä¼š
3. åˆ†æç°æœ‰ä¿¡å·æ•æ‰æ•ˆæœ
4. è‡ªåŠ¨ä¼˜åŒ–ä¿¡å·å‚æ•°
5. ç”Ÿæˆå¤ç›˜æŠ¥å‘Š

Author: Claude
Date: 2026-01-26
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from decimal import Decimal
from loguru import logger
import pymysql
import json
from dataclasses import dataclass, asdict


@dataclass
class BigMoveOpportunity:
    """å¤§è¡Œæƒ…æœºä¼š"""
    symbol: str
    start_time: datetime
    end_time: datetime
    timeframe: str  # '5m', '15m', '1h'
    move_type: str  # 'pump' (ä¸Šæ¶¨), 'dump' (ä¸‹è·Œ)
    price_change_pct: float  # ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”
    volume_ratio: float  # æˆäº¤é‡å€æ•°
    max_price: float
    min_price: float
    start_price: float
    end_price: float

    # ä¿¡å·æ•æ‰æƒ…å†µ
    captured: bool  # æ˜¯å¦æ•æ‰åˆ°
    capture_delay_minutes: Optional[int]  # æ•æ‰å»¶è¿Ÿ(åˆ†é’Ÿ)
    signal_type: Optional[str]  # æ•æ‰çš„ä¿¡å·ç±»å‹
    position_pnl_pct: Optional[float]  # å®é™…ç›ˆäºç™¾åˆ†æ¯”

    # é”™è¿‡åŸå› åˆ†æ
    miss_reason: Optional[str]  # é”™è¿‡çš„åŸå› 


@dataclass
class SignalPerformance:
    """ä¿¡å·è¡¨ç°ç»Ÿè®¡"""
    signal_type: str
    total_signals: int
    captured_opportunities: int  # æ•æ‰åˆ°çš„å¤§è¡Œæƒ…æ•°
    missed_opportunities: int  # é”™è¿‡çš„å¤§è¡Œæƒ…æ•°
    avg_capture_delay: float  # å¹³å‡æ•æ‰å»¶è¿Ÿ(åˆ†é’Ÿ)

    # äº¤æ˜“ç»Ÿè®¡
    total_trades: int
    winning_trades: int
    win_rate: float
    avg_pnl_pct: float
    best_trade_pnl_pct: float
    worst_trade_pnl_pct: float


@dataclass
class ReviewReport:
    """å¤ç›˜æŠ¥å‘Š"""
    date: str
    review_period: str  # '24h'

    # å¤§è¡Œæƒ…ç»Ÿè®¡
    total_opportunities: int
    captured_count: int
    missed_count: int
    capture_rate: float

    # æŒ‰æ—¶é—´å‘¨æœŸç»Ÿè®¡
    opportunities_by_timeframe: Dict[str, int]  # {'5m': 10, '15m': 5, '1h': 2}

    # é”™è¿‡çš„æœºä¼šåˆ—è¡¨
    missed_opportunities: List[BigMoveOpportunity]

    # ä¿¡å·è¡¨ç°
    signal_performances: List[SignalPerformance]

    # ä¼˜åŒ–å»ºè®®
    optimization_suggestions: List[str]

    # å‚æ•°è°ƒæ•´å»ºè®®
    parameter_adjustments: Dict[str, any]


class DailyReviewAnalyzer:
    """æ¯æ—¥å¤ç›˜åˆ†æå™¨"""

    def __init__(self, db_config: dict):
        """
        åˆå§‹åŒ–å¤ç›˜åˆ†æå™¨

        Args:
            db_config: æ•°æ®åº“é…ç½®
        """
        self.db_config = db_config
        self.connection = None

        # å¤§è¡Œæƒ…è¯†åˆ«é˜ˆå€¼
        self.thresholds = {
            '5m': {
                'price_change_min': 0.5,  # æœ€å°ä»·æ ¼å˜åŒ– 0.5%
                'volume_ratio_min': 2.0,   # æœ€å°æˆäº¤é‡å€æ•° 2x
                'duration_candles': 3      # æŒç»­Kçº¿æ•°é‡
            },
            '15m': {
                'price_change_min': 1.0,   # 1.0%
                'volume_ratio_min': 2.0,
                'duration_candles': 2
            },
            '1h': {
                'price_change_min': 2.0,   # 2.0%
                'volume_ratio_min': 1.5,
                'duration_candles': 2
            }
        }

        logger.info("âœ… æ¯æ—¥å¤ç›˜åˆ†æå™¨å·²åˆå§‹åŒ–")

    def _get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        if self.connection is None or not self.connection.open:
            self.connection = pymysql.connect(
                host=self.db_config.get('host', 'localhost'),
                port=self.db_config.get('port', 3306),
                user=self.db_config.get('user', 'root'),
                password=self.db_config.get('password', ''),
                database=self.db_config.get('database', 'binance-data'),
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor
            )
        return self.connection

    async def run_daily_review(self, symbols: List[str]) -> ReviewReport:
        """
        æ‰§è¡Œæ¯æ—¥å¤ç›˜åˆ†æ

        Args:
            symbols: è¦åˆ†æçš„äº¤æ˜“å¯¹åˆ—è¡¨

        Returns:
            å¤ç›˜æŠ¥å‘Š
        """
        logger.info(f"ğŸ” å¼€å§‹æ¯æ—¥å¤ç›˜åˆ†æ | äº¤æ˜“å¯¹æ•°é‡: {len(symbols)}")

        # åˆ†ææ—¶é—´èŒƒå›´: è¿‡å»24å°æ—¶
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)

        # 1. è¯†åˆ«æ‰€æœ‰å¤§è¡Œæƒ…æœºä¼š
        all_opportunities = []

        for symbol in symbols:
            # åˆ†æä¸åŒæ—¶é—´å‘¨æœŸ
            for timeframe in ['5m', '15m', '1h']:
                opportunities = await self._detect_big_moves(
                    symbol, timeframe, start_time, end_time
                )
                all_opportunities.extend(opportunities)

        logger.info(f"ğŸ“Š è¯†åˆ«åˆ° {len(all_opportunities)} ä¸ªå¤§è¡Œæƒ…æœºä¼š")

        # 2. æ£€æŸ¥å“ªäº›æœºä¼šè¢«æ•æ‰åˆ°
        for opp in all_opportunities:
            await self._check_if_captured(opp)

        # 3. ç»Ÿè®¡ä¿¡å·è¡¨ç°
        signal_performances = await self._analyze_signal_performance(start_time, end_time)

        # 4. ç”Ÿæˆä¼˜åŒ–å»ºè®®
        optimization_suggestions = self._generate_optimization_suggestions(
            all_opportunities, signal_performances
        )

        # 5. å‚æ•°è°ƒæ•´å»ºè®®
        parameter_adjustments = self._suggest_parameter_adjustments(
            all_opportunities, signal_performances
        )

        # 6. ç”ŸæˆæŠ¥å‘Š
        captured = [o for o in all_opportunities if o.captured]
        missed = [o for o in all_opportunities if not o.captured]

        timeframe_stats = {}
        for tf in ['5m', '15m', '1h']:
            timeframe_stats[tf] = len([o for o in all_opportunities if o.timeframe == tf])

        report = ReviewReport(
            date=end_time.strftime('%Y-%m-%d'),
            review_period='24h',
            total_opportunities=len(all_opportunities),
            captured_count=len(captured),
            missed_count=len(missed),
            capture_rate=len(captured) / len(all_opportunities) * 100 if all_opportunities else 0,
            opportunities_by_timeframe=timeframe_stats,
            missed_opportunities=missed[:20],  # åªä¿ç•™å‰20ä¸ª
            signal_performances=signal_performances,
            optimization_suggestions=optimization_suggestions,
            parameter_adjustments=parameter_adjustments
        )

        # 7. ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
        await self._save_report(report)

        # 8. ç”Ÿæˆå¯è¯»æŠ¥å‘Š
        self._print_report(report)

        logger.info(f"âœ… å¤ç›˜åˆ†æå®Œæˆ | æ•è·ç‡: {report.capture_rate:.1f}%")

        return report

    async def _detect_big_moves(
        self,
        symbol: str,
        timeframe: str,
        start_time: datetime,
        end_time: datetime
    ) -> List[BigMoveOpportunity]:
        """
        æ£€æµ‹å¤§è¡Œæƒ…æœºä¼š

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´å‘¨æœŸ
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´

        Returns:
            å¤§è¡Œæƒ…æœºä¼šåˆ—è¡¨
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        # è·å–Kçº¿æ•°æ®
        cursor.execute("""
            SELECT
                timestamp,
                open_price,
                high_price,
                low_price,
                close_price,
                volume
            FROM kline_data
            WHERE symbol = %s
            AND timeframe = %s
            AND timestamp >= %s
            AND timestamp <= %s
            AND exchange = 'binance_futures'
            ORDER BY timestamp ASC
        """, (symbol, timeframe, start_time, end_time))

        klines = cursor.fetchall()
        cursor.close()

        if len(klines) < 10:
            return []

        # è®¡ç®—å¹³å‡æˆäº¤é‡
        avg_volume = sum(k['volume'] for k in klines) / len(klines)

        opportunities = []
        threshold = self.thresholds[timeframe]

        # æ»‘åŠ¨çª—å£æ£€æµ‹å¤§è¡Œæƒ…
        window_size = threshold['duration_candles']

        for i in range(len(klines) - window_size + 1):
            window = klines[i:i + window_size]

            # è®¡ç®—çª—å£å†…çš„ä»·æ ¼å˜åŒ–å’Œæˆäº¤é‡
            start_price = float(window[0]['open_price'])
            prices = []
            volumes = []

            for k in window:
                prices.extend([
                    float(k['open_price']),
                    float(k['high_price']),
                    float(k['low_price']),
                    float(k['close_price'])
                ])
                volumes.append(float(k['volume']))

            max_price = max(prices)
            min_price = min(prices)
            end_price = float(window[-1]['close_price'])

            # è®¡ç®—ä»·æ ¼å˜åŒ–å’Œæˆäº¤é‡å€æ•°
            price_change_pct = abs(end_price - start_price) / start_price * 100
            avg_window_volume = sum(volumes) / len(volumes)
            volume_ratio = avg_window_volume / avg_volume if avg_volume > 0 else 0

            # åˆ¤æ–­æ˜¯å¦ä¸ºå¤§è¡Œæƒ…
            if (price_change_pct >= threshold['price_change_min'] and
                volume_ratio >= threshold['volume_ratio_min']):

                move_type = 'pump' if end_price > start_price else 'dump'

                opportunity = BigMoveOpportunity(
                    symbol=symbol,
                    start_time=window[0]['timestamp'],
                    end_time=window[-1]['timestamp'],
                    timeframe=timeframe,
                    move_type=move_type,
                    price_change_pct=price_change_pct if move_type == 'pump' else -price_change_pct,
                    volume_ratio=volume_ratio,
                    max_price=max_price,
                    min_price=min_price,
                    start_price=start_price,
                    end_price=end_price,
                    captured=False,
                    capture_delay_minutes=None,
                    signal_type=None,
                    position_pnl_pct=None,
                    miss_reason=None
                )

                opportunities.append(opportunity)

        return opportunities

    async def _check_if_captured(self, opportunity: BigMoveOpportunity):
        """
        æ£€æŸ¥å¤§è¡Œæƒ…æ˜¯å¦è¢«æ•æ‰åˆ°

        Args:
            opportunity: å¤§è¡Œæƒ…æœºä¼š
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        # æŸ¥æ‰¾åœ¨æœºä¼šæ—¶é—´èŒƒå›´å†…åˆ›å»ºçš„æŒä»“
        # å…è®¸æå‰5åˆ†é’Ÿåˆ°å»¶è¿Ÿ30åˆ†é’Ÿçš„æŒä»“
        search_start = opportunity.start_time - timedelta(minutes=5)
        search_end = opportunity.end_time + timedelta(minutes=30)

        cursor.execute("""
            SELECT
                id,
                symbol,
                direction,
                entry_signal_type,
                entry_signal_time,
                avg_entry_price,
                exit_price,
                realized_pnl_pct,
                created_at
            FROM futures_positions
            WHERE symbol = %s
            AND entry_signal_time >= %s
            AND entry_signal_time <= %s
            AND status = 'closed'
            ORDER BY entry_signal_time ASC
            LIMIT 1
        """, (opportunity.symbol, search_start, search_end))

        position = cursor.fetchone()
        cursor.close()

        if position:
            # æ£€æŸ¥æ–¹å‘æ˜¯å¦åŒ¹é…
            expected_direction = 'LONG' if opportunity.move_type == 'pump' else 'SHORT'

            if position['direction'] == expected_direction:
                # è®¡ç®—æ•æ‰å»¶è¿Ÿ
                delay_seconds = (position['entry_signal_time'] - opportunity.start_time).total_seconds()
                delay_minutes = int(delay_seconds / 60)

                opportunity.captured = True
                opportunity.capture_delay_minutes = delay_minutes
                opportunity.signal_type = position['entry_signal_type']
                opportunity.position_pnl_pct = float(position['realized_pnl_pct']) if position['realized_pnl_pct'] else None

                logger.debug(
                    f"âœ… æ•æ‰åˆ°: {opportunity.symbol} {opportunity.move_type} "
                    f"{opportunity.price_change_pct:.2f}% | å»¶è¿Ÿ{delay_minutes}åˆ†é’Ÿ"
                )
            else:
                opportunity.captured = False
                opportunity.miss_reason = f"æ–¹å‘é”™è¯¯(æœŸæœ›{expected_direction},å®é™…{position['direction']})"
        else:
            opportunity.captured = False
            opportunity.miss_reason = "æœªäº§ç”Ÿä¿¡å·æˆ–æœªå¼€ä»“"

    async def _analyze_signal_performance(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> List[SignalPerformance]:
        """
        åˆ†æä¿¡å·è¡¨ç°

        Args:
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´

        Returns:
            ä¿¡å·è¡¨ç°åˆ—è¡¨
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        # è·å–æ‰€æœ‰ä¿¡å·ç±»å‹çš„ç»Ÿè®¡
        cursor.execute("""
            SELECT
                entry_signal_type,
                COUNT(*) as total_trades,
                SUM(CASE WHEN realized_pnl_pct > 0 THEN 1 ELSE 0 END) as winning_trades,
                AVG(realized_pnl_pct) as avg_pnl_pct,
                MAX(realized_pnl_pct) as best_trade,
                MIN(realized_pnl_pct) as worst_trade
            FROM futures_positions
            WHERE status = 'closed'
            AND close_time >= %s
            AND close_time <= %s
            AND entry_signal_type IS NOT NULL
            GROUP BY entry_signal_type
        """, (start_time, end_time))

        results = cursor.fetchall()
        cursor.close()

        performances = []

        for row in results:
            signal_type = row['entry_signal_type']
            total_trades = row['total_trades']
            winning_trades = row['winning_trades'] or 0

            performance = SignalPerformance(
                signal_type=signal_type,
                total_signals=total_trades,  # ç®€åŒ–ï¼Œå‡è®¾æ¯ä¸ªä¿¡å·éƒ½å¼€ä»“
                captured_opportunities=0,  # éœ€è¦ä»opportunitiesä¸­ç»Ÿè®¡
                missed_opportunities=0,
                avg_capture_delay=0.0,
                total_trades=total_trades,
                winning_trades=winning_trades,
                win_rate=winning_trades / total_trades * 100 if total_trades > 0 else 0,
                avg_pnl_pct=float(row['avg_pnl_pct']) if row['avg_pnl_pct'] else 0,
                best_trade_pnl_pct=float(row['best_trade']) if row['best_trade'] else 0,
                worst_trade_pnl_pct=float(row['worst_trade']) if row['worst_trade'] else 0
            )

            performances.append(performance)

        return performances

    def _generate_optimization_suggestions(
        self,
        opportunities: List[BigMoveOpportunity],
        performances: List[SignalPerformance]
    ) -> List[str]:
        """
        ç”Ÿæˆä¼˜åŒ–å»ºè®®

        Args:
            opportunities: å¤§è¡Œæƒ…æœºä¼šåˆ—è¡¨
            performances: ä¿¡å·è¡¨ç°åˆ—è¡¨

        Returns:
            ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        suggestions = []

        # 1. åˆ†æé”™è¿‡çš„æœºä¼š
        missed = [o for o in opportunities if not o.captured]

        if len(missed) > len(opportunities) * 0.3:  # é”™è¿‡è¶…è¿‡30%
            suggestions.append(
                f"âš ï¸ é”™è¿‡äº†{len(missed)}/{len(opportunities)}ä¸ªå¤§è¡Œæƒ…æœºä¼š ({len(missed)/len(opportunities)*100:.1f}%)ï¼Œ"
                "å»ºè®®é™ä½ä¿¡å·è§¦å‘é˜ˆå€¼"
            )

        # 2. æŒ‰é”™è¿‡åŸå› åˆ†ç±»
        miss_reasons = {}
        for opp in missed:
            reason = opp.miss_reason or "æœªçŸ¥åŸå› "
            miss_reasons[reason] = miss_reasons.get(reason, 0) + 1

        for reason, count in sorted(miss_reasons.items(), key=lambda x: x[1], reverse=True)[:3]:
            suggestions.append(f"ğŸ” ä¸»è¦é”™è¿‡åŸå› : {reason} ({count}æ¬¡)")

        # 3. åˆ†æå»¶è¿Ÿ
        captured_with_delay = [o for o in opportunities if o.captured and o.capture_delay_minutes is not None]

        if captured_with_delay:
            avg_delay = sum(o.capture_delay_minutes for o in captured_with_delay) / len(captured_with_delay)

            if avg_delay > 10:
                suggestions.append(
                    f"â° å¹³å‡æ•æ‰å»¶è¿Ÿ{avg_delay:.1f}åˆ†é’Ÿï¼Œå»ºè®®ä¼˜åŒ–ä¿¡å·æ£€æµ‹é€Ÿåº¦æˆ–é™ä½è§¦å‘æ¡ä»¶"
                )

        # 4. åˆ†æä¿¡å·èƒœç‡
        low_win_rate_signals = [p for p in performances if p.win_rate < 50 and p.total_trades >= 5]

        for perf in low_win_rate_signals:
            suggestions.append(
                f"ğŸ“‰ ä¿¡å· '{perf.signal_type}' èƒœç‡è¾ƒä½({perf.win_rate:.1f}%)ï¼Œ"
                f"å»ºè®®è°ƒæ•´å‚æ•°æˆ–è€ƒè™‘ç¦ç”¨"
            )

        # 5. åˆ†æä¸åŒæ—¶é—´å‘¨æœŸçš„æœºä¼šåˆ†å¸ƒ
        timeframe_counts = {}
        for opp in opportunities:
            timeframe_counts[opp.timeframe] = timeframe_counts.get(opp.timeframe, 0) + 1

        if '5m' in timeframe_counts and timeframe_counts['5m'] > sum(timeframe_counts.values()) * 0.5:
            suggestions.append(
                "ğŸ“Š 5åˆ†é’Ÿçº§åˆ«æœºä¼šè¾ƒå¤šï¼Œå»ºè®®å¢åŠ 5Mé«˜é¢‘ä¿¡å·æ£€æµ‹"
            )

        return suggestions

    def _suggest_parameter_adjustments(
        self,
        opportunities: List[BigMoveOpportunity],
        performances: List[SignalPerformance]
    ) -> Dict[str, any]:
        """
        å»ºè®®å‚æ•°è°ƒæ•´

        Args:
            opportunities: å¤§è¡Œæƒ…æœºä¼šåˆ—è¡¨
            performances: ä¿¡å·è¡¨ç°åˆ—è¡¨

        Returns:
            å‚æ•°è°ƒæ•´å»ºè®®å­—å…¸
        """
        adjustments = {}

        # 1. å¦‚æœé”™è¿‡å¤ªå¤špumpæœºä¼šï¼Œå»ºè®®é™ä½BOTTOM_REVERSAL_LONGé˜ˆå€¼
        missed_pumps = [o for o in opportunities if not o.captured and o.move_type == 'pump']

        if len(missed_pumps) >= 5:
            adjustments['BOTTOM_REVERSAL_LONG'] = {
                'current_threshold': 50,
                'suggested_threshold': 40,
                'reason': f'é”™è¿‡äº†{len(missed_pumps)}ä¸ªä¸Šæ¶¨æœºä¼š'
            }

        # 2. å¦‚æœé”™è¿‡å¤ªå¤šdumpæœºä¼šï¼Œå»ºè®®é™ä½WEAK_RALLY_SHORTé˜ˆå€¼
        missed_dumps = [o for o in opportunities if not o.captured and o.move_type == 'dump']

        if len(missed_dumps) >= 5:
            adjustments['WEAK_RALLY_SHORT'] = {
                'current_threshold': 50,
                'suggested_threshold': 40,
                'reason': f'é”™è¿‡äº†{len(missed_dumps)}ä¸ªä¸‹è·Œæœºä¼š'
            }

        # 3. å¦‚æœå¹³å‡å»¶è¿Ÿå¤ªé«˜ï¼Œå»ºè®®ç¼©çŸ­é‡‡æ ·çª—å£
        captured_with_delay = [o for o in opportunities if o.captured and o.capture_delay_minutes is not None]

        if captured_with_delay:
            avg_delay = sum(o.capture_delay_minutes for o in captured_with_delay) / len(captured_with_delay)

            if avg_delay > 10:
                adjustments['price_sampling'] = {
                    'current_window': '5m',
                    'suggested_window': '3m',
                    'reason': f'å¹³å‡å»¶è¿Ÿ{avg_delay:.1f}åˆ†é’Ÿè¿‡é«˜'
                }

        return adjustments

    async def _save_report(self, report: ReviewReport):
        """
        ä¿å­˜å¤ç›˜æŠ¥å‘Šåˆ°æ•°æ®åº“

        Args:
            report: å¤ç›˜æŠ¥å‘Š
        """
        conn = self._get_connection()
        cursor = conn.cursor()

        try:
            # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS daily_review_reports (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    date DATE NOT NULL,
                    report_json TEXT NOT NULL,
                    total_opportunities INT,
                    captured_count INT,
                    missed_count INT,
                    capture_rate FLOAT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE KEY unique_date (date)
                )
            """)

            # æ’å…¥æˆ–æ›´æ–°æŠ¥å‘Š
            cursor.execute("""
                INSERT INTO daily_review_reports
                (date, report_json, total_opportunities, captured_count, missed_count, capture_rate)
                VALUES (%s, %s, %s, %s, %s, %s)
                ON DUPLICATE KEY UPDATE
                report_json = VALUES(report_json),
                total_opportunities = VALUES(total_opportunities),
                captured_count = VALUES(captured_count),
                missed_count = VALUES(missed_count),
                capture_rate = VALUES(capture_rate)
            """, (
                report.date,
                json.dumps(asdict(report), ensure_ascii=False, default=str),
                report.total_opportunities,
                report.captured_count,
                report.missed_count,
                report.capture_rate
            ))

            conn.commit()
            logger.info(f"ğŸ’¾ å¤ç›˜æŠ¥å‘Šå·²ä¿å­˜åˆ°æ•°æ®åº“: {report.date}")

        except Exception as e:
            logger.error(f"ä¿å­˜å¤ç›˜æŠ¥å‘Šå¤±è´¥: {e}")
            conn.rollback()
        finally:
            cursor.close()

    def _print_report(self, report: ReviewReport):
        """
        æ‰“å°å¤ç›˜æŠ¥å‘Š

        Args:
            report: å¤ç›˜æŠ¥å‘Š
        """
        logger.info("\n" + "="*80)
        logger.info(f"ğŸ“Š æ¯æ—¥å¤ç›˜æŠ¥å‘Š - {report.date}")
        logger.info("="*80)

        logger.info(f"\nã€å¤§è¡Œæƒ…ç»Ÿè®¡ã€‘")
        logger.info(f"  æ€»æœºä¼šæ•°: {report.total_opportunities}")
        logger.info(f"  å·²æ•è·: {report.captured_count} ({report.capture_rate:.1f}%)")
        logger.info(f"  å·²é”™è¿‡: {report.missed_count}")

        logger.info(f"\nã€æŒ‰æ—¶é—´å‘¨æœŸã€‘")
        for tf, count in report.opportunities_by_timeframe.items():
            logger.info(f"  {tf}: {count}ä¸ªæœºä¼š")

        logger.info(f"\nã€é”™è¿‡çš„é‡è¦æœºä¼šã€‘(å‰5ä¸ª)")
        for i, opp in enumerate(report.missed_opportunities[:5], 1):
            logger.info(
                f"  {i}. {opp.symbol} {opp.timeframe} {opp.move_type.upper()} "
                f"{abs(opp.price_change_pct):.2f}% | {opp.volume_ratio:.1f}xé‡èƒ½"
            )
            logger.info(f"     æ—¶é—´: {opp.start_time.strftime('%H:%M')} - {opp.end_time.strftime('%H:%M')}")
            logger.info(f"     åŸå› : {opp.miss_reason}")

        logger.info(f"\nã€ä¿¡å·è¡¨ç°ã€‘")
        for perf in report.signal_performances:
            logger.info(
                f"  {perf.signal_type}: "
                f"{perf.total_trades}ç¬” | "
                f"èƒœç‡{perf.win_rate:.1f}% | "
                f"å¹³å‡{perf.avg_pnl_pct:.2f}%"
            )

        logger.info(f"\nã€ä¼˜åŒ–å»ºè®®ã€‘")
        for suggestion in report.optimization_suggestions:
            logger.info(f"  {suggestion}")

        if report.parameter_adjustments:
            logger.info(f"\nã€å‚æ•°è°ƒæ•´å»ºè®®ã€‘")
            for param, adjustment in report.parameter_adjustments.items():
                logger.info(f"  {param}:")
                logger.info(f"    åŸå› : {adjustment['reason']}")
                if 'current_threshold' in adjustment:
                    logger.info(
                        f"    å»ºè®®: {adjustment['current_threshold']} â†’ "
                        f"{adjustment['suggested_threshold']}"
                    )

        logger.info("\n" + "="*80 + "\n")


async def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    db_config = {
        'host': 'localhost',
        'port': 3306,
        'user': 'root',
        'password': '',
        'database': 'binance-data'
    }

    analyzer = DailyReviewAnalyzer(db_config)

    # æµ‹è¯•äº¤æ˜“å¯¹
    test_symbols = ['BTC/USDT', 'ETH/USDT', 'SOL/USDT', 'BNB/USDT']

    report = await analyzer.run_daily_review(test_symbols)

    print(f"\nå¤ç›˜å®Œæˆï¼æ•è·ç‡: {report.capture_rate:.1f}%")


if __name__ == '__main__':
    asyncio.run(main())
